{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93288141",
   "metadata": {},
   "source": [
    "## Saving in Models and Ziping them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98195280",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p opt/ml/model  \n",
    "!cp model.joblib opt/ml/model/model.joblib\n",
    "!cp imports_featurizer.pkl opt/ml/model/imports_featurizer.pkl\n",
    "!cp section_names_featurizer.pkl opt/ml/model/section_names_featurizer.pkl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "784c6def",
   "metadata": {},
   "source": [
    "# Writing Inference Script"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc154d7",
   "metadata": {},
   "source": [
    "#### This script process the input data on Sagemaker end and returns the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "878b1fb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing inference.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile inference.py\n",
    "import joblib\n",
    "import os\n",
    "import json\n",
    "from scipy.sparse import hstack, csr_matrix\n",
    "from sklearn.feature_extraction.text import HashingVectorizer, TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "import pickle\n",
    "import boto3\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Deserialize fitted model\n",
    "\"\"\"\n",
    "def model_fn(model_dir):\n",
    "    model = joblib.load(os.path.join(model_dir, \"model.joblib\"))\n",
    "    return model\n",
    "\n",
    "\"\"\"\n",
    "input_fn\n",
    "    request_body: The body of the request sent to the model.\n",
    "    request_content_type: (string) specifies the format/variable type of the request\n",
    "\"\"\"\n",
    "def input_fn(request_body, request_content_type):\n",
    "    if request_content_type == 'application/json':\n",
    "        input_data = json.loads(request_body)\n",
    "        return input_data\n",
    "    else:\n",
    "        raise ValueError(\"This model only supports application/json input\")\n",
    "\n",
    "\"\"\"\n",
    "predict_fn\n",
    "    input_data: returned data from input_fn above\n",
    "    model (sklearn model) returned model loaded from model_fn above\n",
    "\"\"\"\n",
    "def predict_fn(input_data, model):\n",
    "    # Process the input data if necessary\n",
    "    processed_data = process_input(input_data)\n",
    "    # Make predictions using the model\n",
    "    predictions = model.predict(processed_data)\n",
    "    #print(predictions)\n",
    "    return predictions\n",
    "\n",
    "def process_input(input_data):\n",
    "    # Process input data as needed before passing to the model for prediction\n",
    "    NgramFeaturesList_pred = np.array(input_data['NgramFeaturesList_pred'])\n",
    "    importsCorpus_pred = input_data['importsCorpus_pred']\n",
    "    sectionNames_pred = input_data['sectionNames_pred']\n",
    "    numSections_pred = int(input_data['numSections_pred'])\n",
    "    \n",
    "\n",
    "    # Load featurizers\n",
    "    imports_featurizer = joblib.load(os.path.join(\"opt/ml/model\", \"imports_featurizer.pkl\"))\n",
    "    section_names_featurizer = joblib.load(os.path.join(\"opt/ml/model\", \"section_names_featurizer.pkl\"))\n",
    "    #print(NgramFeaturesList_pred, importsCorpus_pred, sectionNames_pred, numSections_pred)\n",
    "    #print(imports_featurizer, section_names_featurizer)\n",
    "    # Transform text features\n",
    "    importsCorpus_pred_transformed = imports_featurizer.transform([importsCorpus_pred])\n",
    "    sectionNames_pred_transformed = section_names_featurizer.transform([sectionNames_pred])\n",
    "\n",
    "    # Concatenate features into a single sparse matrix\n",
    "    processed_data = hstack([csr_matrix(NgramFeaturesList_pred),\n",
    "                             importsCorpus_pred_transformed,\n",
    "                             sectionNames_pred_transformed,\n",
    "                             csr_matrix([numSections_pred]).transpose()])\n",
    "    #print(processed_data)\n",
    "    return processed_data\n",
    "\n",
    "\"\"\"\n",
    "output_fn\n",
    "    prediction: the returned value from predict_fn above\n",
    "    content_type: the content type the endpoint expects to be returned. Ex: JSON, string\n",
    "\"\"\"\n",
    "def output_fn(prediction, content_type):\n",
    "    res = int(prediction[0])\n",
    "    respJSON = {'Output': res}\n",
    "    return respJSON\n",
    "\n",
    "\"\"\"if __name__ == '__main__':\n",
    "    predict_fn({'NgramFeaturesList_pred': [[24183, 3382, 304, 17, 923, 636, 358, 275, 128, 635, 358, 613, 389, 384, 448, 12, 380, 170, 307, 122, 224, 203, 51, 338, 521, 111, 395, 215, 175, 419, 264, 397, 287, 106, 487, 236, 16, 277, 459, 594, 469, 241, 155, 163, 158, 230, 215, 443, 80, 46, 44, 216, 68, 42, 36, 48, 161, 29, 240, 145, 139, 52, 20, 75, 99, 33, 224, 161, 38, 226, 729, 139, 27, 168, 19, 68, 269, 271, 236, 33, 197, 207, 337, 1114, 126, 111, 255, 175, 47, 46, 60, 318, 129, 79, 16, 223, 162, 79, 15, 157]],\n",
    " 'importsCorpus_pred': \"kernel32 shlwapi ole32 shell32 user32\",\n",
    " 'sectionNames_pred': \".text .rdata .data .rsrc .reloc\",\n",
    " 'numSections_pred': \"5\"}, model_fn(\"\"))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53e8dfbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.joblib\n",
      "inference.py\n",
      "imports_featurizer.pkl\n",
      "section_names_featurizer.pkl\n",
      "requirements.txt\n",
      "opt/\n",
      "opt/ml/\n",
      "opt/ml/model/\n",
      "opt/ml/model/model.joblib\n",
      "opt/ml/model/imports_featurizer.pkl\n",
      "opt/ml/model/section_names_featurizer.pkl\n"
     ]
    }
   ],
   "source": [
    "!tar -cvpzf model.tar.gz model.joblib inference.py imports_featurizer.pkl section_names_featurizer.pkl requirements.txt opt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee8229f",
   "metadata": {},
   "source": [
    "## Creating requirements.txt file to install missing dependencies on Sagemaker container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1612b00b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile requirements.txt\n",
    "joblib\n",
    "scipy\n",
    "numpy\n",
    "scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72333d13",
   "metadata": {},
   "source": [
    "## Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f263cac2",
   "metadata": {},
   "source": [
    "#### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f42ab433",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import json\n",
    "import os\n",
    "import joblib\n",
    "import pickle\n",
    "import tarfile\n",
    "import sagemaker\n",
    "from sagemaker.estimator import Estimator\n",
    "import time\n",
    "from time import gmtime, strftime\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43af112d",
   "metadata": {},
   "source": [
    "#### Setting up the boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf6c915f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "us-east-1\n"
     ]
    }
   ],
   "source": [
    "#Setup\n",
    "client = boto3.client(service_name=\"sagemaker\")\n",
    "runtime = boto3.client(service_name=\"sagemaker-runtime\")\n",
    "boto_session = boto3.session.Session()\n",
    "s3 = boto_session.resource('s3')\n",
    "region = boto_session.region_name\n",
    "print(region)\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = \"arn:aws:iam::975050199344:role/LabRole\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c698b4f4",
   "metadata": {},
   "source": [
    "#### Retrieving a SKLearn image uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8eb5a370",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve sklearn image\n",
    "image_uri = sagemaker.image_uris.retrieve(\n",
    "    framework=\"sklearn\",\n",
    "    region=region,\n",
    "    version=\"1.2-1\",\n",
    "    py_version=\"py3\",\n",
    "    instance_type=\"ml.t2.medium\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9f6e3e",
   "metadata": {},
   "source": [
    "#### Importing the previously zipped model from S3 Bucket(I have uploaded it manually)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "36f3d2b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker-us-east-1-975050199344\n"
     ]
    }
   ],
   "source": [
    "#Bucket for model artifacts\n",
    "default_bucket = sagemaker_session.default_bucket()\n",
    "print(default_bucket)\n",
    "\n",
    "#Upload tar.gz to bucket\n",
    "model_artifacts = f\"s3://{default_bucket}/model.tar.gz\"\n",
    "response = s3.meta.client.upload_file('model.tar.gz', default_bucket, 'model.tar.gz')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0655484f",
   "metadata": {},
   "source": [
    "#### Creating model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "53b8e983",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model name: sklearn-test2024-04-03-17-02-07\n",
      "Model Arn: arn:aws:sagemaker:us-east-1:975050199344:model/sklearn-test2024-04-03-17-02-07\n"
     ]
    }
   ],
   "source": [
    "#Step 1: Model Creation\n",
    "model_name = \"sklearn-test\" + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "print(\"Model name: \" + model_name)\n",
    "create_model_response = client.create_model(\n",
    "    ModelName=model_name,\n",
    "    Containers=[\n",
    "        {\n",
    "            \"Image\": image_uri,\n",
    "            \"Mode\": \"SingleModel\",\n",
    "            \"ModelDataUrl\": model_artifacts,\n",
    "            \"Environment\": {'SAGEMAKER_SUBMIT_DIRECTORY': model_artifacts,\n",
    "                           'SAGEMAKER_PROGRAM': 'inference.py'} \n",
    "        }\n",
    "    ],\n",
    "    ExecutionRoleArn=role,\n",
    ")\n",
    "print(\"Model Arn: \" + create_model_response[\"ModelArn\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8278cf13",
   "metadata": {},
   "source": [
    "#### Configuring the Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c82bc927",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endpoint Configuration Arn: arn:aws:sagemaker:us-east-1:975050199344:endpoint-config/sklearn-epc2024-04-03-17-02-09\n"
     ]
    }
   ],
   "source": [
    "#Step 2: EPC Creation\n",
    "sklearn_epc_name = \"sklearn-epc\" + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "endpoint_config_response = client.create_endpoint_config(\n",
    "    EndpointConfigName=sklearn_epc_name,\n",
    "    ProductionVariants=[\n",
    "        {\n",
    "            \"VariantName\": \"sklearnvariant\",\n",
    "            \"ModelName\": model_name,\n",
    "            \"InstanceType\": \"ml.t2.medium\",\n",
    "            \"InitialInstanceCount\": 1\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "print(\"Endpoint Configuration Arn: \" + endpoint_config_response[\"EndpointConfigArn\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2272d37e",
   "metadata": {},
   "source": [
    "#### Creating Endpoint on Sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6abeabaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endpoint Arn: arn:aws:sagemaker:us-east-1:975050199344:endpoint/sklearn-local-ep2024-04-03-17-02-11\n"
     ]
    }
   ],
   "source": [
    "#Step 3: EP Creation\n",
    "endpoint_name = \"sklearn-local-ep\" + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "create_endpoint_response = client.create_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    EndpointConfigName=sklearn_epc_name,\n",
    ")\n",
    "print(\"Endpoint Arn: \" + create_endpoint_response[\"EndpointArn\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "866ef69b",
   "metadata": {},
   "source": [
    "#### Monitoring code snippet of deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "37d583a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "InService\n",
      "{'EndpointName': 'sklearn-local-ep2024-04-03-17-02-11', 'EndpointArn': 'arn:aws:sagemaker:us-east-1:975050199344:endpoint/sklearn-local-ep2024-04-03-17-02-11', 'EndpointConfigName': 'sklearn-epc2024-04-03-17-02-09', 'ProductionVariants': [{'VariantName': 'sklearnvariant', 'DeployedImages': [{'SpecifiedImage': '683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-scikit-learn:1.2-1-cpu-py3', 'ResolvedImage': '683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-scikit-learn@sha256:0381fc23e5c6ee7a0a944240dbaf6041688cb1e439af23e0c930da072ac9e971', 'ResolutionTime': datetime.datetime(2024, 4, 3, 17, 2, 12, 287000, tzinfo=tzlocal())}], 'CurrentWeight': 1.0, 'DesiredWeight': 1.0, 'CurrentInstanceCount': 1, 'DesiredInstanceCount': 1}], 'EndpointStatus': 'InService', 'CreationTime': datetime.datetime(2024, 4, 3, 17, 2, 11, 593000, tzinfo=tzlocal()), 'LastModifiedTime': datetime.datetime(2024, 4, 3, 17, 7, 41, 134000, tzinfo=tzlocal()), 'ResponseMetadata': {'RequestId': '7410dc8a-83b5-4b87-bb1d-0cf898d43386', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': '7410dc8a-83b5-4b87-bb1d-0cf898d43386', 'content-type': 'application/x-amz-json-1.1', 'content-length': '767', 'date': 'Wed, 03 Apr 2024 17:07:46 GMT'}, 'RetryAttempts': 0}}\n"
     ]
    }
   ],
   "source": [
    "#Monitor creation\n",
    "describe_endpoint_response = client.describe_endpoint(EndpointName=endpoint_name)\n",
    "while describe_endpoint_response[\"EndpointStatus\"] == \"Creating\":\n",
    "    describe_endpoint_response = client.describe_endpoint(EndpointName=endpoint_name)\n",
    "    print(describe_endpoint_response[\"EndpointStatus\"])\n",
    "    time.sleep(15)\n",
    "print(describe_endpoint_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba209dd",
   "metadata": {},
   "source": [
    "#### Testing the Endpoint is working or not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a0b12a67",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "An error occurred (ValidationError) when calling the InvokeEndpoint operation: Endpoint sklearn-local-ep2024-03-31-08-06-32 of account 975050199344 not found.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 22\u001b[0m\n\u001b[1;32m     19\u001b[0m endpoint_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msklearn-local-ep2024-03-31-08-06-32\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Call the endpoint\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mruntime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke_endpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mEndpointName\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mendpoint_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43mContentType\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mapplication/json\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43mBody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpayload\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# Decode and print the response\u001b[39;00m\n\u001b[1;32m     27\u001b[0m result \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(response[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBody\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mread()\u001b[38;5;241m.\u001b[39mdecode())\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/client.py:553\u001b[0m, in \u001b[0;36mClientCreator._create_api_method.<locals>._api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    549\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    550\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpy_operation_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m() only accepts keyword arguments.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    551\u001b[0m     )\n\u001b[1;32m    552\u001b[0m \u001b[38;5;66;03m# The \"self\" in this scope is referring to the BaseClient.\u001b[39;00m\n\u001b[0;32m--> 553\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_api_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43moperation_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/client.py:1009\u001b[0m, in \u001b[0;36mBaseClient._make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m   1005\u001b[0m     error_code \u001b[38;5;241m=\u001b[39m error_info\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQueryErrorCode\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m error_info\u001b[38;5;241m.\u001b[39mget(\n\u001b[1;32m   1006\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCode\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1007\u001b[0m     )\n\u001b[1;32m   1008\u001b[0m     error_class \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mfrom_code(error_code)\n\u001b[0;32m-> 1009\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error_class(parsed_response, operation_name)\n\u001b[1;32m   1010\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1011\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parsed_response\n",
      "\u001b[0;31mValidationError\u001b[0m: An error occurred (ValidationError) when calling the InvokeEndpoint operation: Endpoint sklearn-local-ep2024-03-31-08-06-32 of account 975050199344 not found."
     ]
    }
   ],
   "source": [
    "import json\n",
    "import boto3\n",
    "\n",
    "# Initialize the SageMaker runtime client\n",
    "runtime = boto3.client('sagemaker-runtime')\n",
    "\n",
    "# Define your input data\n",
    "input_data = {\n",
    "    'NgramFeaturesList_pred': [[24183, 3382, 304, 17, 923, 636, 358, 275, 128, 635, 358, 613, 389, 384, 448, 12, 380, 170, 307, 122, 224, 203, 51, 338, 521, 111, 395, 215, 175, 419, 264, 397, 287, 106, 487, 236, 16, 277, 459, 594, 469, 241, 155, 163, 158, 230, 215, 443, 80, 46, 44, 216, 68, 42, 36, 48, 161, 29, 240, 145, 139, 52, 20, 75, 99, 33, 224, 161, 38, 226, 729, 139, 27, 168, 19, 68, 269, 271, 236, 33, 197, 207, 337, 1114, 126, 111, 255, 175, 47, 46, 60, 318, 129, 79, 16, 223, 162, 79, 15, 157]],\n",
    "    'importsCorpus_pred': \"kernel32 shlwapi ole32 shell32 user32\",\n",
    "    'sectionNames_pred': \".text .rdata .data .rsrc .reloc\",\n",
    "    'numSections_pred': \"5\"\n",
    "}\n",
    "\n",
    "# Convert input data to JSON string\n",
    "payload = json.dumps(input_data)\n",
    "\n",
    "# Specify the endpoint name\n",
    "endpoint_name = 'sklearn-local-ep2024-03-31-08-06-32'\n",
    "\n",
    "# Call the endpoint\n",
    "response = runtime.invoke_endpoint(EndpointName=endpoint_name,\n",
    "                                   ContentType='application/json',\n",
    "                                   Body=payload)\n",
    "\n",
    "# Decode and print the response\n",
    "result = json.loads(response['Body'].read().decode())\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e45cd8",
   "metadata": {},
   "source": [
    "### It is working perfectly!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19554489",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
