{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93288141",
   "metadata": {},
   "source": [
    "## Saving in Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98195280",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p opt/ml/model  \n",
    "!cp model.joblib opt/ml/model/model.joblib\n",
    "!cp imports_featurizer.pkl opt/ml/model/imports_featurizer.pkl\n",
    "!cp section_names_featurizer.pkl opt/ml/model/section_names_featurizer.pkl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "784c6def",
   "metadata": {},
   "source": [
    "# Writing Inference Script"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc154d7",
   "metadata": {},
   "source": [
    "### This script handles input data on the Sagemaker platform, processing it and providing predictions as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "878b1fb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing inference.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile inference.py\n",
    "import joblib\n",
    "import os\n",
    "import json\n",
    "from scipy.sparse import hstack, csr_matrix\n",
    "from sklearn.feature_extraction.text import HashingVectorizer, TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "import pickle\n",
    "import boto3\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Deserialize fitted model\n",
    "\"\"\"\n",
    "def model_fn(model_dir):\n",
    "    model = joblib.load(os.path.join(model_dir, \"model.joblib\"))\n",
    "    return model\n",
    "\n",
    "\"\"\"\n",
    "input_fn\n",
    "    request_body: The body of the request sent to the model.\n",
    "    request_content_type: (string) specifies the format/variable type of the request\n",
    "\"\"\"\n",
    "def input_fn(request_body, request_content_type):\n",
    "    if request_content_type == 'application/json':\n",
    "        input_data = json.loads(request_body)\n",
    "        return input_data\n",
    "    else:\n",
    "        raise ValueError(\"This model only supports application/json input\")\n",
    "\n",
    "\"\"\"\n",
    "predict_fn\n",
    "    input_data: returned data from input_fn above\n",
    "    model (sklearn model) returned model loaded from model_fn above\n",
    "\"\"\"\n",
    "def predict_fn(input_data, model):\n",
    "    # Process the input data if necessary\n",
    "    processed_data = process_input(input_data)\n",
    "    # Make predictions using the model\n",
    "    predictions = model.predict(processed_data)\n",
    "    #print(predictions)\n",
    "    return predictions\n",
    "\n",
    "def process_input(input_data):\n",
    "    # Process input data as needed before passing to the model for prediction\n",
    "    NgramFeaturesList_pred = np.array(input_data['NgramFeaturesList_pred'])\n",
    "    importsCorpus_pred = input_data['importsCorpus_pred']\n",
    "    sectionNames_pred = input_data['sectionNames_pred']\n",
    "    numSections_pred = int(input_data['numSections_pred'])\n",
    "    \n",
    "\n",
    "    # Load featurizers\n",
    "    imports_featurizer = joblib.load(os.path.join(\"opt/ml/model\", \"imports_featurizer.pkl\"))\n",
    "    section_names_featurizer = joblib.load(os.path.join(\"opt/ml/model\", \"section_names_featurizer.pkl\"))\n",
    "    #print(NgramFeaturesList_pred, importsCorpus_pred, sectionNames_pred, numSections_pred)\n",
    "    #print(imports_featurizer, section_names_featurizer)\n",
    "    # Transform text features\n",
    "    importsCorpus_pred_transformed = imports_featurizer.transform([importsCorpus_pred])\n",
    "    sectionNames_pred_transformed = section_names_featurizer.transform([sectionNames_pred])\n",
    "\n",
    "    # Concatenate features into a single sparse matrix\n",
    "    processed_data = hstack([csr_matrix(NgramFeaturesList_pred),\n",
    "                             importsCorpus_pred_transformed,\n",
    "                             sectionNames_pred_transformed,\n",
    "                             csr_matrix([numSections_pred]).transpose()])\n",
    "    #print(processed_data)\n",
    "    return processed_data\n",
    "\n",
    "\"\"\"\n",
    "output_fn\n",
    "    prediction: the returned value from predict_fn above\n",
    "    content_type: the content type the endpoint expects to be returned. Ex: JSON, string\n",
    "\"\"\"\n",
    "def output_fn(prediction, content_type):\n",
    "    res = int(prediction[0])\n",
    "    respJSON = {'Output': res}\n",
    "    return respJSON\n",
    "\n",
    "\"\"\"if __name__ == '__main__':\n",
    "    predict_fn({'NgramFeaturesList_pred': [[24183, 3382, 304, 17, 923, 636, 358, 275, 128, 635, 358, 613, 389, 384, 448, 12, 380, 170, 307, 122, 224, 203, 51, 338, 521, 111, 395, 215, 175, 419, 264, 397, 287, 106, 487, 236, 16, 277, 459, 594, 469, 241, 155, 163, 158, 230, 215, 443, 80, 46, 44, 216, 68, 42, 36, 48, 161, 29, 240, 145, 139, 52, 20, 75, 99, 33, 224, 161, 38, 226, 729, 139, 27, 168, 19, 68, 269, 271, 236, 33, 197, 207, 337, 1114, 126, 111, 255, 175, 47, 46, 60, 318, 129, 79, 16, 223, 162, 79, 15, 157]],\n",
    " 'importsCorpus_pred': \"kernel32 shlwapi ole32 shell32 user32\",\n",
    " 'sectionNames_pred': \".text .rdata .data .rsrc .reloc\",\n",
    " 'numSections_pred': \"5\"}, model_fn(\"\"))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b899048c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Zipping the Model and necessary files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53e8dfbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.joblib\n",
      "inference.py\n",
      "imports_featurizer.pkl\n",
      "section_names_featurizer.pkl\n",
      "requirements.txt\n",
      "opt/\n",
      "opt/ml/\n",
      "opt/ml/model/\n",
      "opt/ml/model/model.joblib\n",
      "opt/ml/model/imports_featurizer.pkl\n",
      "opt/ml/model/section_names_featurizer.pkl\n"
     ]
    }
   ],
   "source": [
    "!tar -cvpzf model.tar.gz model.joblib inference.py imports_featurizer.pkl section_names_featurizer.pkl requirements.txt opt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee8229f",
   "metadata": {},
   "source": [
    "## Creating requirements.txt file to install missing dependencies on Sagemaker container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1612b00b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile requirements.txt\n",
    "joblib\n",
    "scipy\n",
    "numpy\n",
    "scikit-learn == 1.2.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72333d13",
   "metadata": {},
   "source": [
    "## Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f263cac2",
   "metadata": {},
   "source": [
    "### Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f42ab433",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import json\n",
    "import os\n",
    "import joblib\n",
    "import pickle\n",
    "import tarfile\n",
    "import sagemaker\n",
    "from sagemaker.estimator import Estimator\n",
    "import time\n",
    "from time import gmtime, strftime\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43af112d",
   "metadata": {},
   "source": [
    "### Connecting to Model S3 Bucket "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf6c915f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "us-east-1\n"
     ]
    }
   ],
   "source": [
    "#Setup\n",
    "client = boto3.client(service_name=\"sagemaker\")\n",
    "runtime = boto3.client(service_name=\"sagemaker-runtime\")\n",
    "boto_session = boto3.session.Session()\n",
    "s3 = boto_session.resource('s3')\n",
    "region = boto_session.region_name\n",
    "print(region)\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = \"arn:aws:iam::975050199344:role/LabRole\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c698b4f4",
   "metadata": {},
   "source": [
    "### Retrieving a SKLearn image uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8eb5a370",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve sklearn image\n",
    "image_uri = sagemaker.image_uris.retrieve(\n",
    "    framework=\"sklearn\",\n",
    "    region=region,\n",
    "    version=\"1.2-1\",\n",
    "    py_version=\"py3\",\n",
    "    instance_type=\"ml.t2.medium\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9f6e3e",
   "metadata": {},
   "source": [
    "### Importing the zipped model from S3 Bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "36f3d2b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker-us-east-1-975050199344\n"
     ]
    }
   ],
   "source": [
    "#Bucket for model artifacts\n",
    "default_bucket = sagemaker_session.default_bucket()\n",
    "print(default_bucket)\n",
    "\n",
    "#Upload tar.gz to bucket\n",
    "model_artifacts = f\"s3://{default_bucket}/model.tar.gz\"\n",
    "response = s3.meta.client.upload_file('model.tar.gz', default_bucket, 'model.tar.gz')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0655484f",
   "metadata": {},
   "source": [
    "### Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "53b8e983",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model name: sklearn-test2024-04-03-17-02-07\n",
      "Model Arn: arn:aws:sagemaker:us-east-1:975050199344:model/sklearn-test2024-04-03-17-02-07\n"
     ]
    }
   ],
   "source": [
    "#Step 1: Model Creation\n",
    "model_name = \"sklearn-test\" + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "print(\"Model name: \" + model_name)\n",
    "create_model_response = client.create_model(\n",
    "    ModelName=model_name,\n",
    "    Containers=[\n",
    "        {\n",
    "            \"Image\": image_uri,\n",
    "            \"Mode\": \"SingleModel\",\n",
    "            \"ModelDataUrl\": model_artifacts,\n",
    "            \"Environment\": {'SAGEMAKER_SUBMIT_DIRECTORY': model_artifacts,\n",
    "                           'SAGEMAKER_PROGRAM': 'inference.py'} \n",
    "        }\n",
    "    ],\n",
    "    ExecutionRoleArn=role,\n",
    ")\n",
    "print(\"Model Arn: \" + create_model_response[\"ModelArn\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8278cf13",
   "metadata": {},
   "source": [
    "### EPC Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c82bc927",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endpoint Configuration Arn: arn:aws:sagemaker:us-east-1:975050199344:endpoint-config/sklearn-epc2024-04-03-17-02-09\n"
     ]
    }
   ],
   "source": [
    "#Step 2: EPC Creation\n",
    "sklearn_epc_name = \"sklearn-epc\" + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "endpoint_config_response = client.create_endpoint_config(\n",
    "    EndpointConfigName=sklearn_epc_name,\n",
    "    ProductionVariants=[\n",
    "        {\n",
    "            \"VariantName\": \"sklearnvariant\",\n",
    "            \"ModelName\": model_name,\n",
    "            \"InstanceType\": \"ml.t2.medium\",\n",
    "            \"InitialInstanceCount\": 1\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "print(\"Endpoint Configuration Arn: \" + endpoint_config_response[\"EndpointConfigArn\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2272d37e",
   "metadata": {},
   "source": [
    "### Endpoint Creation on Sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6abeabaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endpoint Arn: arn:aws:sagemaker:us-east-1:975050199344:endpoint/sklearn-local-ep2024-04-03-17-02-11\n"
     ]
    }
   ],
   "source": [
    "#Step 3: EP Creation\n",
    "endpoint_name = \"sklearn-local-ep\" + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "create_endpoint_response = client.create_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    EndpointConfigName=sklearn_epc_name,\n",
    ")\n",
    "print(\"Endpoint Arn: \" + create_endpoint_response[\"EndpointArn\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "866ef69b",
   "metadata": {},
   "source": [
    "### Monitoring Deployment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "37d583a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "InService\n",
      "{'EndpointName': 'sklearn-local-ep2024-04-03-17-02-11', 'EndpointArn': 'arn:aws:sagemaker:us-east-1:975050199344:endpoint/sklearn-local-ep2024-04-03-17-02-11', 'EndpointConfigName': 'sklearn-epc2024-04-03-17-02-09', 'ProductionVariants': [{'VariantName': 'sklearnvariant', 'DeployedImages': [{'SpecifiedImage': '683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-scikit-learn:1.2-1-cpu-py3', 'ResolvedImage': '683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-scikit-learn@sha256:0381fc23e5c6ee7a0a944240dbaf6041688cb1e439af23e0c930da072ac9e971', 'ResolutionTime': datetime.datetime(2024, 4, 3, 17, 2, 12, 287000, tzinfo=tzlocal())}], 'CurrentWeight': 1.0, 'DesiredWeight': 1.0, 'CurrentInstanceCount': 1, 'DesiredInstanceCount': 1}], 'EndpointStatus': 'InService', 'CreationTime': datetime.datetime(2024, 4, 3, 17, 2, 11, 593000, tzinfo=tzlocal()), 'LastModifiedTime': datetime.datetime(2024, 4, 3, 17, 7, 41, 134000, tzinfo=tzlocal()), 'ResponseMetadata': {'RequestId': '7410dc8a-83b5-4b87-bb1d-0cf898d43386', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': '7410dc8a-83b5-4b87-bb1d-0cf898d43386', 'content-type': 'application/x-amz-json-1.1', 'content-length': '767', 'date': 'Wed, 03 Apr 2024 17:07:46 GMT'}, 'RetryAttempts': 0}}\n"
     ]
    }
   ],
   "source": [
    "#Monitor creation\n",
    "describe_endpoint_response = client.describe_endpoint(EndpointName=endpoint_name)\n",
    "while describe_endpoint_response[\"EndpointStatus\"] == \"Creating\":\n",
    "    describe_endpoint_response = client.describe_endpoint(EndpointName=endpoint_name)\n",
    "    print(describe_endpoint_response[\"EndpointStatus\"])\n",
    "    time.sleep(30)\n",
    "print(describe_endpoint_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba209dd",
   "metadata": {},
   "source": [
    "### Testing the Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0b12a67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Output': 1}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import boto3\n",
    "\n",
    "# Initialize the SageMaker runtime client\n",
    "runtime = boto3.client('sagemaker-runtime')\n",
    "\n",
    "# Define your input data\n",
    "input_data = {\n",
    "    'NgramFeaturesList_pred': [[106318,10490,2550,14,1779,1590,771,828,189,1279,807,1627,1001,1031,12,1064,821,390,335,684,791,498,68,944,1278,770,225,570,608,404,702,991,634,277,989,14,735,717,840,541,980,203,283,585,449,376,885,15,28,177,22,14,635,118,21,242,392,133,470,197,91,142,2893,755,119,49,26,731,56,503,29,367,284,301,134,18,465,594,499,546,386,9,342,560,352,242,454,505,161,18,326,46,366,290,76,208,559,142,425,191]],\n",
    "    'importsCorpus_pred': \"kernel32 shlwapi ole32 shell32 user32\",\n",
    "    'sectionNames_pred': \".text .rdata .data .rsrc .reloc\",\n",
    "    'numSections_pred': \"5\"\n",
    "}\n",
    "\n",
    "# Convert input data to JSON string\n",
    "payload = json.dumps(input_data)\n",
    "\n",
    "# Specify the endpoint name\n",
    "endpoint_name = 'sklearn-local-ep2024-04-03-17-02-11'\n",
    "\n",
    "# Call the endpoint\n",
    "response = runtime.invoke_endpoint(EndpointName=endpoint_name,\n",
    "                                   ContentType='application/json',\n",
    "                                   Body=payload)\n",
    "\n",
    "# Decode and print the response\n",
    "result = json.loads(response['Body'].read().decode())\n",
    "print(result)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
